{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3800 Tópicos en CC - NLP UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versiones de librerías, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- nltk 3.7\n",
    "- spacy 3.5.1\n",
    "- sklearn \n",
    "- keras 2.9.0\n",
    "- tensorflow 2.9.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python3 -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "sp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = sp(\"Paredes bate el record de Chamaco Valdes y deja a la U en zona de descenso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paredes        PROPN          \n",
      "bate           VERB           \n",
      "el             DET            \n",
      "record         NOUN           \n",
      "de             ADP            \n",
      "Chamaco        PROPN          \n",
      "Valdes         PROPN          \n",
      "y              CCONJ          \n",
      "deja           VERB           \n",
      "a              ADP            \n",
      "la             DET            \n",
      "U              PROPN          \n",
      "en             ADP            \n",
      "zona           NOUN           \n",
      "de             ADP            \n",
      "descenso       NOUN           \n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(str(word.text).ljust(15) + str(word.pos_).ljust(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamaco Valdes - PER - Named person or family.\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Paredes bate el record de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chamaco Valdes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " y deja a la U en zona de descenso</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a POS tagger from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.' 'Vinken' 'is' 'chairman' 'of' 'Elsevier' 'N.V.' ',' 'the' 'Dutch'\n",
      " 'publishing' 'group' '.']\n",
      "['NNP' 'NNP' 'VBZ' 'NN' 'IN' 'NNP' 'NNP' ',' 'DT' 'NNP' 'VBG' 'NN' '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "sentences, sentence_tags =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    " \n",
    "print(sentences[1])\n",
    "print(sentence_tags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "(train_sentences, test_sentences,  train_tags,  test_tags) = train_test_split(sentences, sentence_tags, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = set([]), set([])\n",
    " \n",
    "for s in train_sentences:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    " \n",
    "for ts in train_tags:\n",
    "    for t in ts:\n",
    "        tags.add(t)\n",
    " \n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0   # The special value used to padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-RRB-', 'WDT', 'EX', 'WP', 'RBS', 'DT', '-NONE-', 'VBP', 'JJ', 'CC', 'IN', ',', '-LRB-', 'PRP$', 'SYM', 'VBN', 'PRP', 'NNP', 'CD', '``', 'FW', 'WRB', 'PDT', 'POS', '#', 'LS', 'NNPS', 'MD', 'JJR', 'RP', 'VBG', 'WP$', 'VB', \"''\", '.', '$', 'JJS', 'VBD', 'UH', 'VBZ', 'RBR', 'NN', 'TO', 'NNS', ':', 'RB'}\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[981, 158, 8849, 9279, 7953, 3291, 2944, 9499, 5911, 7748, 8125, 4947, 5957, 10198, 8069, 1985, 5250, 348, 8125, 5462, 9909, 7589, 1784, 1340, 1660, 10032, 6467, 3061, 9909, 2163, 97, 5590, 10198, 1603, 2850, 5250]\n",
      "[1722, 7514, 4197, 1607, 9773, 208, 6927, 8226, 9389, 8986, 1100, 1066, 1888, 1867, 10042, 4449, 7953, 3291, 8770, 1985, 3303, 3026, 8770, 9831, 2579, 8440, 1985, 981, 158, 8849, 9279, 2171, 2850]\n",
      "[18, 18, 40, 7, 18, 18, 40, 18, 10, 18, 20, 46, 9, 9, 44, 12, 34, 11, 20, 11, 7, 31, 44, 11, 17, 17, 8, 16, 7, 43, 33, 14, 9, 42, 35, 34]\n",
      "[9, 42, 44, 46, 8, 42, 44, 33, 42, 10, 6, 11, 14, 42, 11, 6, 18, 18, 42, 12, 10, 9, 42, 44, 8, 6, 12, 18, 18, 40, 7, 7, 35]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
    " \n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    " \n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    " \n",
    "for s in train_tags:\n",
    "    train_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "for s in test_tags:\n",
    "    test_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  981   158  8849  9279  7953  3291  2944  9499  5911  7748  8125  4947\n",
      "  5957 10198  8069  1985  5250   348  8125  5462  9909  7589  1784  1340\n",
      "  1660 10032  6467  3061  9909  2163    97  5590 10198  1603  2850  5250\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0]\n",
      "[ 1722  7514  4197  1607  9773   208  6927  8226  9389  8986  1100  1066\n",
      "  1888  1867 10042  4449  7953  3291  8770  1985  3303  3026  8770  9831\n",
      "  2579  8440  1985   981   158  8849  9279  2171  2850     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0]\n",
      "[18 18 40  7 18 18 40 18 10 18 20 46  9  9 44 12 34 11 20 11  7 31 44 11\n",
      " 17 17  8 16  7 43 33 14  9 42 35 34  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[ 9 42 44 46  8 42 44 33 42 10  6 11 14 42 11  6 18 18 42 12 10  9 42 44\n",
      "  8  6 12 18 18 40  7  7 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 271, 128)          1337984   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 271, 512)         788480    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 271, 47)          24111     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 271, 47)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,150,575\n",
      "Trainable params: 2,150,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    " \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy', ignore_class_accuracy(0)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "23/23 [==============================] - 31s 1s/step - loss: 1.1532 - accuracy: 0.8648 - ignore_accuracy: 0.0338 - val_loss: 0.3507 - val_accuracy: 0.9108 - val_ignore_accuracy: 0.1266\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.3290 - accuracy: 0.9053 - ignore_accuracy: 0.0526 - val_loss: 0.3086 - val_accuracy: 0.9103 - val_ignore_accuracy: 0.1094\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.3085 - accuracy: 0.9145 - ignore_accuracy: 0.1307 - val_loss: 0.2963 - val_accuracy: 0.9188 - val_ignore_accuracy: 0.1318\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2978 - accuracy: 0.9171 - ignore_accuracy: 0.1357 - val_loss: 0.2876 - val_accuracy: 0.9190 - val_ignore_accuracy: 0.1330\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2889 - accuracy: 0.9173 - ignore_accuracy: 0.1380 - val_loss: 0.2796 - val_accuracy: 0.9198 - val_ignore_accuracy: 0.1409\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2799 - accuracy: 0.9196 - ignore_accuracy: 0.1599 - val_loss: 0.2711 - val_accuracy: 0.9246 - val_ignore_accuracy: 0.1892\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2719 - accuracy: 0.9238 - ignore_accuracy: 0.2010 - val_loss: 0.2631 - val_accuracy: 0.9325 - val_ignore_accuracy: 0.2745\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2637 - accuracy: 0.9301 - ignore_accuracy: 0.2703 - val_loss: 0.2558 - val_accuracy: 0.9357 - val_ignore_accuracy: 0.3103\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2522 - accuracy: 0.9363 - ignore_accuracy: 0.3370 - val_loss: 0.2414 - val_accuracy: 0.9416 - val_ignore_accuracy: 0.3734\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2318 - accuracy: 0.9435 - ignore_accuracy: 0.4120 - val_loss: 0.2163 - val_accuracy: 0.9482 - val_ignore_accuracy: 0.4449\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2000 - accuracy: 0.9507 - ignore_accuracy: 0.4857 - val_loss: 0.1820 - val_accuracy: 0.9546 - val_ignore_accuracy: 0.5141\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.1640 - accuracy: 0.9572 - ignore_accuracy: 0.5545 - val_loss: 0.1504 - val_accuracy: 0.9605 - val_ignore_accuracy: 0.5780\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.1326 - accuracy: 0.9660 - ignore_accuracy: 0.6478 - val_loss: 0.1241 - val_accuracy: 0.9676 - val_ignore_accuracy: 0.6555\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.1073 - accuracy: 0.9740 - ignore_accuracy: 0.7298 - val_loss: 0.1039 - val_accuracy: 0.9750 - val_ignore_accuracy: 0.7351\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0863 - accuracy: 0.9810 - ignore_accuracy: 0.8030 - val_loss: 0.0888 - val_accuracy: 0.9786 - val_ignore_accuracy: 0.7738\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0691 - accuracy: 0.9857 - ignore_accuracy: 0.8517 - val_loss: 0.0733 - val_accuracy: 0.9838 - val_ignore_accuracy: 0.8290\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0546 - accuracy: 0.9893 - ignore_accuracy: 0.8875 - val_loss: 0.0628 - val_accuracy: 0.9863 - val_ignore_accuracy: 0.8567\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0434 - accuracy: 0.9918 - ignore_accuracy: 0.9145 - val_loss: 0.0535 - val_accuracy: 0.9879 - val_ignore_accuracy: 0.8729\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0351 - accuracy: 0.9933 - ignore_accuracy: 0.9284 - val_loss: 0.0477 - val_accuracy: 0.9889 - val_ignore_accuracy: 0.8833\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0290 - accuracy: 0.9945 - ignore_accuracy: 0.9435 - val_loss: 0.0437 - val_accuracy: 0.9900 - val_ignore_accuracy: 0.8946\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0242 - accuracy: 0.9953 - ignore_accuracy: 0.9511 - val_loss: 0.0411 - val_accuracy: 0.9905 - val_ignore_accuracy: 0.9012\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0207 - accuracy: 0.9960 - ignore_accuracy: 0.9571 - val_loss: 0.0383 - val_accuracy: 0.9909 - val_ignore_accuracy: 0.9047\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0180 - accuracy: 0.9965 - ignore_accuracy: 0.9636 - val_loss: 0.0374 - val_accuracy: 0.9910 - val_ignore_accuracy: 0.9071\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0158 - accuracy: 0.9969 - ignore_accuracy: 0.9673 - val_loss: 0.0350 - val_accuracy: 0.9913 - val_ignore_accuracy: 0.9090\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0141 - accuracy: 0.9972 - ignore_accuracy: 0.9708 - val_loss: 0.0346 - val_accuracy: 0.9916 - val_ignore_accuracy: 0.9119\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0126 - accuracy: 0.9974 - ignore_accuracy: 0.9730 - val_loss: 0.0339 - val_accuracy: 0.9917 - val_ignore_accuracy: 0.9134\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0115 - accuracy: 0.9976 - ignore_accuracy: 0.9753 - val_loss: 0.0334 - val_accuracy: 0.9918 - val_ignore_accuracy: 0.9142\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0105 - accuracy: 0.9978 - ignore_accuracy: 0.9763 - val_loss: 0.0326 - val_accuracy: 0.9919 - val_ignore_accuracy: 0.9154\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0096 - accuracy: 0.9980 - ignore_accuracy: 0.9792 - val_loss: 0.0316 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9147\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0091 - accuracy: 0.9980 - ignore_accuracy: 0.9793 - val_loss: 0.0346 - val_accuracy: 0.9916 - val_ignore_accuracy: 0.9126\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0084 - accuracy: 0.9982 - ignore_accuracy: 0.9804 - val_loss: 0.0316 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9175\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0077 - accuracy: 0.9984 - ignore_accuracy: 0.9836 - val_loss: 0.0326 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9173\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0071 - accuracy: 0.9985 - ignore_accuracy: 0.9841 - val_loss: 0.0319 - val_accuracy: 0.9922 - val_ignore_accuracy: 0.9200\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0066 - accuracy: 0.9987 - ignore_accuracy: 0.9859 - val_loss: 0.0335 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9170\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0063 - accuracy: 0.9987 - ignore_accuracy: 0.9853 - val_loss: 0.0319 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9176\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0058 - accuracy: 0.9988 - ignore_accuracy: 0.9871 - val_loss: 0.0326 - val_accuracy: 0.9921 - val_ignore_accuracy: 0.9183\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0054 - accuracy: 0.9989 - ignore_accuracy: 0.9885 - val_loss: 0.0332 - val_accuracy: 0.9919 - val_ignore_accuracy: 0.9167\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0051 - accuracy: 0.9990 - ignore_accuracy: 0.9892 - val_loss: 0.0315 - val_accuracy: 0.9921 - val_ignore_accuracy: 0.9176\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0048 - accuracy: 0.9990 - ignore_accuracy: 0.9901 - val_loss: 0.0319 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9170\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0045 - accuracy: 0.9991 - ignore_accuracy: 0.9910 - val_loss: 0.0329 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26b87f3850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 174ms/step - loss: 0.0330 - accuracy: 0.9919 - ignore_accuracy: 0.9156\n",
      "accuracy: 99.18856620788574\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\"running is very important for me\".split(), \"I was running every day for a month\".split()]\n",
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    " \n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "predictions = model.predict(test_samples_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNS', 'VBZ', 'RB', 'JJ', 'IN', 'PRP']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})[0][:len(test_samples[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VBD', 'VBG', 'DT', 'NN', 'IN', 'DT', 'NN']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})[1][:len(test_samples[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
