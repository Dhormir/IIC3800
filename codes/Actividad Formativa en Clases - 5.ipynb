{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3800 Tópicos en CC - NLP UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versiones de librerías, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- nltk 3.7\n",
    "- gensim 4.1.2\n",
    "- keras 2.9.0\n",
    "- tensorflow 2.9.1\n",
    "- instant-distance 0.3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGS = ('en', 'es') # fíjese que aquí modifique fr por es\n",
    "LANG_REPLACE = '$$lang'\n",
    "WORD_MAP_PATH = f\"./data/{'_'.join(LANGS)}.json\"\n",
    "BUILT_IDX_PATH = f\"./data/{'_'.join(LANGS)}.idx\"\n",
    "DL_TEMPLATE = f\"https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.{LANG_REPLACE}.align.vec\"\n",
    "\n",
    "points = []\n",
    "values = []\n",
    "word_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________\n",
    "\n",
    "## Actividad en clase\n",
    "\n",
    "Construya un traductor de palabras  **inglés-castellano** usando FastText. Luego, construya un traductor **castellano-inglés**. Para esto haga lo siguiente:\n",
    "\n",
    "- Cree el diccionario **word_map** (vea el ejemplo de clases).\n",
    "- Construya el motor de vecinos cercanos sobre el embedding space usando la librería **instant_distance**.\n",
    "- Busque las cinco palabras en castellano más cercanas a **hello**.\n",
    "- Ahora cree el diccionario **word_map_reverse** para que pueda traducir desde castellano a inglés.\n",
    "- Construya el motor de vecinos cercanos sobre el embedding space usando la librería **instant_distance**.\n",
    "- Busque las cinco palabras en inglés más cercanas a **hola**.\n",
    "- Cuanto termine, me avisa para entregarle una **L (logrado)**.\n",
    "- Recuerde que las L otorgan un bono en la nota final de la asignatura.\n",
    "\n",
    "\n",
    "***Tiene hasta el final de la clase.***\n",
    "\n",
    "_________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-727d1ade74cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlineno\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0;31m# EOF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/aiohttp/streams.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaduntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreaduntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/aiohttp/streams.py\u001b[0m in \u001b[0;36mreaduntil\u001b[0;34m(self, separator)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnot_enough\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"readuntil\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/aiohttp/streams.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, func_name)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                     \u001b[0;32mawait\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/aiohttp/helpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cancelled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, aiohttp\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "  for lang in LANGS:\n",
    "    # Construct a url for each language\n",
    "    url = DL_TEMPLATE.replace(LANG_REPLACE, lang)\n",
    "\n",
    "    # Ensure the directory and files exist\n",
    "    os.makedirs(os.path.dirname(BUILT_IDX_PATH), exist_ok=True)\n",
    "\n",
    "    lineno = 0\n",
    "    async with session.get(url) as resp:\n",
    "      while True:\n",
    "        lineno += 1\n",
    "        line = await resp.content.readline()\n",
    "        if not line:\n",
    "          # EOF\n",
    "          break\n",
    "\n",
    "        linestr = line.decode('utf-8')\n",
    "        tokens = linestr.split(' ')\n",
    "\n",
    "        # The first token is the word and the rest\n",
    "        # are the embedding\n",
    "        value = tokens[0]\n",
    "        embedding = [float(p) for p in tokens[1:]]\n",
    "\n",
    "        # We only go from english to the other two languages\n",
    "        if lang == 'en':\n",
    "          word_map[value] = embedding\n",
    "        else:\n",
    "          # Don't index words that exist in english\n",
    "          # to improve the quality of the results.\n",
    "          if value in word_map:\n",
    "              continue\n",
    "\n",
    "          # We track values here to build the instant-distance index\n",
    "          # Every value is prepended with 2 character language code.\n",
    "          # This allows us to determine language output later.\n",
    "          values.append(lang + value)\n",
    "          points.append(embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instant_distance, json\n",
    "\n",
    "# Build the instant-distance index and dump it out to a file with .idx suffix\n",
    "print('Building index... (this will take a while)')\n",
    "hnsw = instant_distance.HnswMap.build(points, values, instant_distance.Config())\n",
    "hnsw.dump(BUILT_IDX_PATH)\n",
    "\n",
    "# Store the mapping from string to embedding in a .json file\n",
    "with open(WORD_MAP_PATH, 'w') as f:\n",
    "    json.dump(word_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'hello'\n",
    "\n",
    "# Get an embedding for the given word\n",
    "embedding = word_map.get(word)\n",
    "if not embedding:\n",
    "  print(f\"Word not recognized: {word}\")\n",
    "  exit(1)\n",
    "\n",
    "hnsw = instant_distance.HnswMap.load(BUILT_IDX_PATH)\n",
    "search = instant_distance.Search()\n",
    "hnsw.search(embedding, search)\n",
    "\n",
    "# Print the results\n",
    "for result in list(search)[:5]:\n",
    "  # We know that the first two characters of the value is the language code\n",
    "  # from when we built the index.\n",
    "  print(result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGS = ('es', 'en')\n",
    "LANG_REPLACE = '$$lang'\n",
    "WORD_MAP_PATH = f\"./data/{'_'.join(LANGS)}.json\"\n",
    "BUILT_IDX_PATH = f\"./data/{'_'.join(LANGS)}.idx\"\n",
    "DL_TEMPLATE = f\"https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.{LANG_REPLACE}.align.vec\"\n",
    "\n",
    "points = []\n",
    "values = []\n",
    "word_map = {}\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "  for lang in LANGS:\n",
    "    # Construct a url for each language\n",
    "    url = DL_TEMPLATE.replace(LANG_REPLACE, lang)\n",
    "\n",
    "    # Ensure the directory and files exist\n",
    "    os.makedirs(os.path.dirname(BUILT_IDX_PATH), exist_ok=True)\n",
    "\n",
    "    lineno = 0\n",
    "    async with session.get(url) as resp:\n",
    "      while True:\n",
    "        lineno += 1\n",
    "        line = await resp.content.readline()\n",
    "        if not line:\n",
    "          # EOF\n",
    "          break\n",
    "\n",
    "        linestr = line.decode('utf-8')\n",
    "        tokens = linestr.split(' ')\n",
    "\n",
    "        # The first token is the word and the rest\n",
    "        # are the embedding\n",
    "        value = tokens[0]\n",
    "        embedding = [float(p) for p in tokens[1:]]\n",
    "\n",
    "        # We only go from english to the other two languages\n",
    "        if lang == 'es':\n",
    "          word_map[value] = embedding\n",
    "        else:\n",
    "          # Don't index words that exist in spanish\n",
    "          # to improve the quality of the results.\n",
    "          if value in word_map:\n",
    "              continue\n",
    "\n",
    "          # We track values here to build the instant-distance index\n",
    "          # Every value is prepended with 2 character language code.\n",
    "          # This allows us to determine language output later.\n",
    "          values.append(lang + value)\n",
    "          points.append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the instant-distance index and dump it out to a file with .idx suffix\n",
    "print('Building index... (this will take a while)')\n",
    "hnsw = instant_distance.HnswMap.build(points, values, instant_distance.Config())\n",
    "hnsw.dump(BUILT_IDX_PATH)\n",
    "\n",
    "# Store the mapping from string to embedding in a .json file\n",
    "with open(WORD_MAP_PATH, 'w') as f:\n",
    "    json.dump(word_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'hola'\n",
    "\n",
    "# Get an embedding for the given word\n",
    "embedding = word_map.get(word)\n",
    "if not embedding:\n",
    "  print(f\"Word not recognized: {word}\")\n",
    "  exit(1)\n",
    "\n",
    "hnsw = instant_distance.HnswMap.load(BUILT_IDX_PATH)\n",
    "search = instant_distance.Search()\n",
    "hnsw.search(embedding, search)\n",
    "\n",
    "# Print the results\n",
    "for result in list(search)[:4]:\n",
    "  # We know that the first two characters of the value is the language code\n",
    "  # from when we built the index.\n",
    "  print(result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
